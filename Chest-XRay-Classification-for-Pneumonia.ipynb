{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](sample_img/pexels-linkedin-sales-navigator-2182972.jpg)\n",
    "image optain from pexel.com\n",
    "#  Chest X-Ray Classification for Pneumonia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-challenge\" data-toc-modified-id=\"The-challenge-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>The challenge</a></span></li><li><span><a href=\"#Proposed-solution\" data-toc-modified-id=\"Proposed-solution-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Proposed solution</a></span></li><li><span><a href=\"#Model-evaluation\" data-toc-modified-id=\"Model-evaluation-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Model evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Precision\" data-toc-modified-id=\"Precision-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Precision</a></span></li></ul></li><li><span><a href=\"#Recall\" data-toc-modified-id=\"Recall-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Recall</a></span></li><li><span><a href=\"#F1-Score\" data-toc-modified-id=\"F1-Score-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>F1 Score</a></span></li><li><span><a href=\"#Accuracy\" data-toc-modified-id=\"Accuracy-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Accuracy</a></span></li><li><span><a href=\"#Conclusion-on-evaluation-metric\" data-toc-modified-id=\"Conclusion-on-evaluation-metric-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Conclusion on evaluation metric</a></span></li></ul></li><li><span><a href=\"#The-Data\" data-toc-modified-id=\"The-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>The Data</a></span></li><li><span><a href=\"#Project-Setup\" data-toc-modified-id=\"Project-Setup-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Project Setup</a></span></li><li><span><a href=\"#XGBoost\" data-toc-modified-id=\"XGBoost-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>XGBoost</a></span></li><li><span><a href=\"#Keras-CNN-from-scratch\" data-toc-modified-id=\"Keras-CNN-from-scratch-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Keras CNN from scratch</a></span><ul class=\"toc-item\"><li><span><a href=\"#Basic\" data-toc-modified-id=\"Basic-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Basic</a></span></li><li><span><a href=\"#Data-generation\" data-toc-modified-id=\"Data-generation-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Data generation</a></span></li><li><span><a href=\"#Model-creation\" data-toc-modified-id=\"Model-creation-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Model creation</a></span></li><li><span><a href=\"#Train-the-model\" data-toc-modified-id=\"Train-the-model-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Train the model</a></span></li><li><span><a href=\"#How-did-the-training-go?\" data-toc-modified-id=\"How-did-the-training-go?-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>How did the training go?</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "### The challenge\n",
    "The rise in medical imaging has had the benefit of providing early detection of desease leading to early intervention. It has also resulted in reduced use of invasive procedures. And with increase in data the burden in medical experts examining that data increases.\n",
    "<p></p>\n",
    "According to this [article](https://www.gehealthcare.com/article/beyond-imagingthe-paradox-of-ai-and-medical-imaging-innovation) hospitals are producing 50 petabytes of data per yea resultin in 90% of all healthcare data. And this [article](https://missinglink.ai/guides/deep-learning-healthcare/what-you-need-to-know-about-deep-learning-medical-imaging/) states - 'The number of medical images that emergency room radiologists have to analyze can be overwhelming, with each medical study involving up to 3,000 images taking up 250GB of data.'\n",
    "<p></p>\n",
    "Therefore, we are in an age where there has been rapid growth in medical image acquisition as well as running challenging and interesting analysis on them. In addition, the overwhelming load of data and the need for rapid analysis is a recipe for error.\n",
    "\n",
    "### Proposed solution\n",
    "This is where technologies such as machine learning and deep learning can help to reduce the burden on the technicians and doctors. These technologies can also be beneficial if it is demonstrated that they are able to find patterns in images that are not easily detectable through human inspection. \n",
    "\n",
    "We propose to explore the employment of `Machine Learning` and `Deep Learning` algorithms to aid in the analysis of medical images. Specifically, this effort will focus on the analysis of chest X-ray images of patients to determine whether or not they had pneumonia.\n",
    "\n",
    "The approach that we take is to build several models of different types and tuning which are then compared to determine the best performing model. The models are built using both the XGBoost classification algorithm and Convolutonal Neural Networks (CNN) based on the Keras / Tensorflow framework.\n",
    "\n",
    "### Model evaluation\n",
    "The models are evaluted on how acurrately they predict desease. In this case it is desired to have a high rate of `True Positives` and low rate of `False Negative`. This is because higher the `False Negative` the greater the number of deseased cases that are missed. It is preffered to misdiagnose as having desease, which would lead to furthur analysis, than missing the desease. The later could lead to a loss of valuable time in treatment.\n",
    "\n",
    "Therefore, the metric that we use needs to consider the high cost associated with `False Negative`. Here is a review of the options.\n",
    "\n",
    "#### Precision\n",
    "$\\Large precision = \\frac{TP}{TP + FP}$\n",
    "\n",
    "The focus of precision is the cost of high `False Positive` results. It measures the cost of patients being incorrectly diagnosed as having the desease. While this is a problem, it is not as significant as being misdiagnose as not having the desease.\n",
    "\n",
    "### Recall\n",
    "$\\Large recall = \\frac{TP}{TP + FN}$\n",
    "\n",
    "Recall focuses on the cost of `False Negative` results. This would seem to be the metric that our models should be evaluated on. By reducing the number of `False Negative`, the model can will reduce the number of deseased patients that are missed in diagnosis.\n",
    "\n",
    "### F1 Score\n",
    "$\\Large f1 score = 2 x \\frac{precision * recall}{precisoin + recall}$\n",
    "\n",
    "This measure strikes a balance between `precision` and `recall`. While this seems to be a good compromise, you have to consider the the compromise might come at the cost of a higher recall than acceptable.\n",
    "\n",
    "### Accuracy\n",
    "$\\Large accuracy = \\frac{TP+TN}{TP+TN+FP+FN}$\n",
    "\n",
    "This metric carries a higher probability of misclassification.\n",
    "\n",
    "### Conclusion on evaluation metric\n",
    "Base on the above, it is clear that recall is the metric that best addresses the problem. It gives a higher cost to `False Negative` results, meaning that less patients with desease will be misdiagnosed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "The dataset comes from Kermany et al. on [Mendeley](https://data.mendeley.com/datasets/rscbjbr9sj/3). There is also a version on [Kaggle](https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia) which is a subset of the Mendeley dataset. However, the code for downloading the dataset is included in the Jupyter Notebook titled `01-Project_setup.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Setup\n",
    "The notebook titled `*01-Project_setup.ipynb*` contains code that does the following:\n",
    "1. Creates the `artifacts` directory tree structure.\n",
    "2. Creates the `data` directory tree structure.\n",
    "3. Downloads the zipped data from Mendeley.com\n",
    "4. Creates the `train`, `valid`, and `test` folders \n",
    "5. Unzips the zipped files into the proper folder.\n",
    "6. Creates a folder called preprocessed to hold augmented data\n",
    "7. Runs augmentation on the `train` dataset which is heavily imbalanced on the side of deseased.\n",
    "8. Copies files from `train` into the preprocessed folder to create a larger dataset.\n",
    "9. Processes the data in preprocossed including flattening all of the image arrays so that they can be process by XGBoost.\n",
    "10. Save the flatten images into numpy array to be used later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "`XGBoost` is a library that implements a gradient boosting tree algorithm. I has become extremely popular in Kaggle competitions. In this experiment two `XGBoost` models are created. The first model is created using the default parameters. Then `Baysian Optimization` is used to find the optimal parameters in the second model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras CNN from scratch\n",
    "In this experiment we create two Keras / Tensorflow CNN models. They are very basic and only differ in the number of layers.\n",
    "### Basic \n",
    "### Data generation\n",
    "We use an Keras ImageDataGenerator to augment the data. The code can be found in the notebooke titled `*03-Basic CNN model.ipynb*`\n",
    "```Python\n",
    "train_batch = batch_make(train_path, ['NORMAL', 'PNEUMONIA'], batch_size=20)\n",
    "valid_batch = batch_make(valid_path, ['NORMAL', 'PNEUMONIA'], batch_size=20)\n",
    "test_batch = batch_make(test_path, ['NORMAL', 'PNEUMONIA'], batch_size=20, shuffle=False)\n",
    "```\n",
    "### Model creation\n",
    "We created a simple convolutional neural network consisting of two convolutional layers with max pooling, and an output layer with two nodes. Below is the configuration.\n",
    "\n",
    "```python\n",
    "model = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding = 'same', input_shape=(224,224,3)),\n",
    "    MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'),\n",
    "    MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "    Flatten(),\n",
    "    Dense(units=2, activation='softmax')\n",
    "])\n",
    "\n",
    "```\n",
    "### Train the model\n",
    "The model is trained for 100 epochs.\n",
    "```python\n",
    "history_1 = model.fit(x=train_batch,\n",
    "                      steps_per_epoch=len(train_batch),\n",
    "                      validation_data=valid_batch,\n",
    "                      validation_steps=len(valid_batch),\n",
    "                      epochs=100,\n",
    "                      verbose=2\n",
    "                      )\n",
    "```\n",
    "Epoch 1/100\n",
    "210/210 - 1532s - loss: 0.3867 - accuracy: 0.8232 - val_loss: 0.2814 - val_accuracy: 0.8701\n",
    "Epoch 2/100\n",
    "210/210 - 104s - loss: 0.2613 - accuracy: 0.8908 - val_loss: 0.2403 - val_accuracy: 0.9064\n",
    "Epoch 3/100\n",
    "210/210 - 104s - loss: 0.2472 - accuracy: 0.8906 - val_loss: 0.2281 - val_accuracy: 0.9007\n",
    "Epoch 4/100\n",
    "210/210 - 104s - loss: 0.2427 - accuracy: 0.8956 - val_loss: 0.2286 - val_accuracy: 0.9179\n",
    "Epoch 5/100\n",
    "210/210 - 103s - loss: 0.2357 - accuracy: 0.9059 - val_loss: 0.2385 - val_accuracy: 0.9121\n",
    "Epoch 6/100\n",
    "210/210 - 103s - loss: 0.2299 - accuracy: 0.9023 - val_loss: 0.2172 - val_accuracy: 0.9188\n",
    "Epoch 7/100\n",
    "210/210 - 102s - loss: 0.2078 - accuracy: 0.9147 - val_loss: 0.2030 - val_accuracy: 0.9312\n",
    "Epoch 8/100\n",
    "210/210 - 102s - loss: 0.2167 - accuracy: 0.9097 - val_loss: 0.2141 - val_accuracy: 0.9160\n",
    "Epoch 9/100\n",
    "210/210 - 102s - loss: 0.2100 - accuracy: 0.9176 - val_loss: 0.2128 - val_accuracy: 0.9188\n",
    "Epoch 10/100\n",
    "210/210 - 102s - loss: 0.2064 - accuracy: 0.9109 - val_loss: 0.2227 - val_accuracy: 0.9074\n",
    "Epoch 11/100\n",
    "210/210 - 102s - loss: 0.2065 - accuracy: 0.9183 - val_loss: 0.1775 - val_accuracy: 0.9245\n",
    "Epoch 12/100\n",
    "210/210 - 102s - loss: 0.2050 - accuracy: 0.9173 - val_loss: 0.1916 - val_accuracy: 0.9255\n",
    "Epoch 13/100\n",
    "210/210 - 101s - loss: 0.2003 - accuracy: 0.9188 - val_loss: 0.2402 - val_accuracy: 0.8997\n",
    "Epoch 14/100\n",
    "210/210 - 101s - loss: 0.2023 - accuracy: 0.9221 - val_loss: 0.2370 - val_accuracy: 0.9045\n",
    "Epoch 15/100\n",
    "210/210 - 101s - loss: 0.1929 - accuracy: 0.9214 - val_loss: 0.1757 - val_accuracy: 0.9293\n",
    "Epoch 16/100\n",
    "210/210 - 101s - loss: 0.1786 - accuracy: 0.9252 - val_loss: 0.1970 - val_accuracy: 0.9274\n",
    "Epoch 17/100\n",
    "210/210 - 100s - loss: 0.1828 - accuracy: 0.9324 - val_loss: 0.1841 - val_accuracy: 0.9322\n",
    "Epoch 18/100\n",
    "210/210 - 99s - loss: 0.1835 - accuracy: 0.9274 - val_loss: 0.1825 - val_accuracy: 0.9226\n",
    "Epoch 19/100\n",
    "210/210 - 100s - loss: 0.1847 - accuracy: 0.9240 - val_loss: 0.1734 - val_accuracy: 0.9360\n",
    "Epoch 20/100\n",
    "210/210 - 100s - loss: 0.1768 - accuracy: 0.9295 - val_loss: 0.1657 - val_accuracy: 0.9427\n",
    "Epoch 21/100\n",
    "210/210 - 100s - loss: 0.1796 - accuracy: 0.9274 - val_loss: 0.1582 - val_accuracy: 0.9456\n",
    "Epoch 22/100\n",
    "210/210 - 100s - loss: 0.1750 - accuracy: 0.9295 - val_loss: 0.1644 - val_accuracy: 0.9322\n",
    "Epoch 23/100\n",
    "210/210 - 100s - loss: 0.1724 - accuracy: 0.9333 - val_loss: 0.1697 - val_accuracy: 0.9360\n",
    "Epoch 24/100\n",
    "210/210 - 100s - loss: 0.1745 - accuracy: 0.9338 - val_loss: 0.1778 - val_accuracy: 0.9255\n",
    "Epoch 25/100\n",
    "210/210 - 101s - loss: 0.1739 - accuracy: 0.9333 - val_loss: 0.1881 - val_accuracy: 0.9331\n",
    "Epoch 26/100\n",
    "210/210 - 100s - loss: 0.1867 - accuracy: 0.9278 - val_loss: 0.1671 - val_accuracy: 0.9351\n",
    "Epoch 27/100\n",
    "210/210 - 100s - loss: 0.1670 - accuracy: 0.9329 - val_loss: 0.1864 - val_accuracy: 0.9265\n",
    "Epoch 28/100\n",
    "210/210 - 101s - loss: 0.1580 - accuracy: 0.9424 - val_loss: 0.1672 - val_accuracy: 0.9322\n",
    "Epoch 29/100\n",
    "210/210 - 101s - loss: 0.1744 - accuracy: 0.9309 - val_loss: 0.1779 - val_accuracy: 0.9236\n",
    "Epoch 30/100\n",
    "210/210 - 102s - loss: 0.1701 - accuracy: 0.9329 - val_loss: 0.1927 - val_accuracy: 0.9303\n",
    "Epoch 31/100\n",
    "210/210 - 102s - loss: 0.1585 - accuracy: 0.9391 - val_loss: 0.1315 - val_accuracy: 0.9542\n",
    "Epoch 32/100\n",
    "210/210 - 102s - loss: 0.1691 - accuracy: 0.9321 - val_loss: 0.1557 - val_accuracy: 0.9360\n",
    "Epoch 33/100\n",
    "210/210 - 102s - loss: 0.1571 - accuracy: 0.9395 - val_loss: 0.1602 - val_accuracy: 0.9408\n",
    "Epoch 34/100\n",
    "210/210 - 102s - loss: 0.1604 - accuracy: 0.9398 - val_loss: 0.1562 - val_accuracy: 0.9379\n",
    "Epoch 35/100\n",
    "210/210 - 101s - loss: 0.1628 - accuracy: 0.9326 - val_loss: 0.1901 - val_accuracy: 0.9293\n",
    "Epoch 36/100\n",
    "210/210 - 100s - loss: 0.1720 - accuracy: 0.9297 - val_loss: 0.1542 - val_accuracy: 0.9398\n",
    "Epoch 37/100\n",
    "210/210 - 101s - loss: 0.1497 - accuracy: 0.9427 - val_loss: 0.1774 - val_accuracy: 0.9303\n",
    "Epoch 38/100\n",
    "210/210 - 100s - loss: 0.1590 - accuracy: 0.9395 - val_loss: 0.1579 - val_accuracy: 0.9370\n",
    "Epoch 39/100\n",
    "210/210 - 100s - loss: 0.1590 - accuracy: 0.9362 - val_loss: 0.1788 - val_accuracy: 0.9198\n",
    "Epoch 40/100\n",
    "210/210 - 100s - loss: 0.1599 - accuracy: 0.9374 - val_loss: 0.1540 - val_accuracy: 0.9408\n",
    "Epoch 41/100\n",
    "210/210 - 100s - loss: 0.1455 - accuracy: 0.9436 - val_loss: 0.1481 - val_accuracy: 0.9475\n",
    "Epoch 42/100\n",
    "210/210 - 100s - loss: 0.1637 - accuracy: 0.9362 - val_loss: 0.1530 - val_accuracy: 0.9379\n",
    "Epoch 43/100\n",
    "210/210 - 101s - loss: 0.1568 - accuracy: 0.9403 - val_loss: 0.1642 - val_accuracy: 0.9331\n",
    "Epoch 44/100\n",
    "210/210 - 100s - loss: 0.1623 - accuracy: 0.9364 - val_loss: 0.1315 - val_accuracy: 0.9475\n",
    "Epoch 45/100\n",
    "210/210 - 100s - loss: 0.1496 - accuracy: 0.9448 - val_loss: 0.1723 - val_accuracy: 0.9312\n",
    "Epoch 46/100\n",
    "210/210 - 100s - loss: 0.1465 - accuracy: 0.9453 - val_loss: 0.1474 - val_accuracy: 0.9436\n",
    "Epoch 47/100\n",
    "210/210 - 100s - loss: 0.1463 - accuracy: 0.9446 - val_loss: 0.1367 - val_accuracy: 0.9446\n",
    "Epoch 48/100\n",
    "210/210 - 99s - loss: 0.1498 - accuracy: 0.9412 - val_loss: 0.1478 - val_accuracy: 0.9513\n",
    "Epoch 49/100\n",
    "210/210 - 101s - loss: 0.1428 - accuracy: 0.9427 - val_loss: 0.1550 - val_accuracy: 0.9398\n",
    "Epoch 50/100\n",
    "210/210 - 101s - loss: 0.1480 - accuracy: 0.9427 - val_loss: 0.1270 - val_accuracy: 0.9532\n",
    "Epoch 51/100\n",
    "210/210 - 100s - loss: 0.1475 - accuracy: 0.9424 - val_loss: 0.1395 - val_accuracy: 0.9427\n",
    "Epoch 52/100\n",
    "210/210 - 100s - loss: 0.1432 - accuracy: 0.9455 - val_loss: 0.1279 - val_accuracy: 0.9522\n",
    "Epoch 53/100\n",
    "210/210 - 100s - loss: 0.1496 - accuracy: 0.9398 - val_loss: 0.1538 - val_accuracy: 0.9303\n",
    "Epoch 54/100\n",
    "210/210 - 99s - loss: 0.1476 - accuracy: 0.9427 - val_loss: 0.1351 - val_accuracy: 0.9494\n",
    "Epoch 55/100\n",
    "210/210 - 100s - loss: 0.1500 - accuracy: 0.9407 - val_loss: 0.1465 - val_accuracy: 0.9398\n",
    "Epoch 56/100\n",
    "210/210 - 100s - loss: 0.1364 - accuracy: 0.9491 - val_loss: 0.1400 - val_accuracy: 0.9456\n",
    "Epoch 57/100\n",
    "210/210 - 100s - loss: 0.1437 - accuracy: 0.9438 - val_loss: 0.1960 - val_accuracy: 0.9150\n",
    "Epoch 58/100\n",
    "210/210 - 100s - loss: 0.1408 - accuracy: 0.9470 - val_loss: 0.1351 - val_accuracy: 0.9513\n",
    "Epoch 59/100\n",
    "210/210 - 100s - loss: 0.1387 - accuracy: 0.9472 - val_loss: 0.1366 - val_accuracy: 0.9465\n",
    "Epoch 60/100\n",
    "210/210 - 100s - loss: 0.1497 - accuracy: 0.9424 - val_loss: 0.1417 - val_accuracy: 0.9484\n",
    "Epoch 61/100\n",
    "210/210 - 100s - loss: 0.1407 - accuracy: 0.9455 - val_loss: 0.1871 - val_accuracy: 0.9312\n",
    "Epoch 62/100\n",
    "210/210 - 100s - loss: 0.1439 - accuracy: 0.9446 - val_loss: 0.1365 - val_accuracy: 0.9398\n",
    "Epoch 63/100\n",
    "210/210 - 100s - loss: 0.1371 - accuracy: 0.9455 - val_loss: 0.1742 - val_accuracy: 0.9417\n",
    "Epoch 64/100\n",
    "210/210 - 100s - loss: 0.1322 - accuracy: 0.9534 - val_loss: 0.1302 - val_accuracy: 0.9465\n",
    "Epoch 65/100\n",
    "210/210 - 101s - loss: 0.1501 - accuracy: 0.9424 - val_loss: 0.1312 - val_accuracy: 0.9417\n",
    "Epoch 66/100\n",
    "210/210 - 100s - loss: 0.1320 - accuracy: 0.9455 - val_loss: 0.1514 - val_accuracy: 0.9408\n",
    "Epoch 67/100\n",
    "210/210 - 100s - loss: 0.1362 - accuracy: 0.9460 - val_loss: 0.1238 - val_accuracy: 0.9542\n",
    "Epoch 68/100\n",
    "210/210 - 101s - loss: 0.1362 - accuracy: 0.9465 - val_loss: 0.1525 - val_accuracy: 0.9427\n",
    "Epoch 69/100\n",
    "210/210 - 100s - loss: 0.1305 - accuracy: 0.9517 - val_loss: 0.1547 - val_accuracy: 0.9503\n",
    "Epoch 70/100\n",
    "210/210 - 100s - loss: 0.1353 - accuracy: 0.9496 - val_loss: 0.1165 - val_accuracy: 0.9484\n",
    "Epoch 71/100\n",
    "210/210 - 100s - loss: 0.1391 - accuracy: 0.9491 - val_loss: 0.1215 - val_accuracy: 0.9551\n",
    "Epoch 72/100\n",
    "210/210 - 100s - loss: 0.1410 - accuracy: 0.9481 - val_loss: 0.1923 - val_accuracy: 0.9322\n",
    "Epoch 73/100\n",
    "210/210 - 100s - loss: 0.1388 - accuracy: 0.9455 - val_loss: 0.1274 - val_accuracy: 0.9465\n",
    "Epoch 74/100\n",
    "210/210 - 101s - loss: 0.1327 - accuracy: 0.9520 - val_loss: 0.1341 - val_accuracy: 0.9494\n",
    "Epoch 75/100\n",
    "210/210 - 100s - loss: 0.1282 - accuracy: 0.9529 - val_loss: 0.1208 - val_accuracy: 0.9580\n",
    "Epoch 76/100\n",
    "210/210 - 100s - loss: 0.1262 - accuracy: 0.9505 - val_loss: 0.1445 - val_accuracy: 0.9427\n",
    "Epoch 77/100\n",
    "210/210 - 100s - loss: 0.1286 - accuracy: 0.9493 - val_loss: 0.1027 - val_accuracy: 0.9647\n",
    "Epoch 78/100\n",
    "210/210 - 100s - loss: 0.1325 - accuracy: 0.9498 - val_loss: 0.1518 - val_accuracy: 0.9331\n",
    "Epoch 79/100\n",
    "210/210 - 100s - loss: 0.1330 - accuracy: 0.9458 - val_loss: 0.1928 - val_accuracy: 0.9179\n",
    "Epoch 80/100\n",
    "210/210 - 101s - loss: 0.1252 - accuracy: 0.9544 - val_loss: 0.1319 - val_accuracy: 0.9503\n",
    "Epoch 81/100\n",
    "210/210 - 100s - loss: 0.1373 - accuracy: 0.9431 - val_loss: 0.1352 - val_accuracy: 0.9427\n",
    "Epoch 82/100\n",
    "210/210 - 100s - loss: 0.1285 - accuracy: 0.9501 - val_loss: 0.1304 - val_accuracy: 0.9408\n",
    "Epoch 83/100\n",
    "210/210 - 101s - loss: 0.1278 - accuracy: 0.9458 - val_loss: 0.1162 - val_accuracy: 0.9580\n",
    "Epoch 84/100\n",
    "210/210 - 100s - loss: 0.1276 - accuracy: 0.9522 - val_loss: 0.1205 - val_accuracy: 0.9542\n",
    "Epoch 85/100\n",
    "210/210 - 100s - loss: 0.1226 - accuracy: 0.9558 - val_loss: 0.1371 - val_accuracy: 0.9503\n",
    "Epoch 86/100\n",
    "210/210 - 101s - loss: 0.1288 - accuracy: 0.9503 - val_loss: 0.1106 - val_accuracy: 0.9561\n",
    "Epoch 87/100\n",
    "210/210 - 100s - loss: 0.1188 - accuracy: 0.9589 - val_loss: 0.1233 - val_accuracy: 0.9542\n",
    "Epoch 88/100\n",
    "210/210 - 100s - loss: 0.1169 - accuracy: 0.9599 - val_loss: 0.1168 - val_accuracy: 0.9494\n",
    "Epoch 89/100\n",
    "210/210 - 100s - loss: 0.1272 - accuracy: 0.9541 - val_loss: 0.1089 - val_accuracy: 0.9618\n",
    "Epoch 90/100\n",
    "210/210 - 100s - loss: 0.1211 - accuracy: 0.9544 - val_loss: 0.1298 - val_accuracy: 0.9446\n",
    "Epoch 91/100\n",
    "210/210 - 100s - loss: 0.1254 - accuracy: 0.9548 - val_loss: 0.1306 - val_accuracy: 0.9551\n",
    "Epoch 92/100\n",
    "210/210 - 100s - loss: 0.1269 - accuracy: 0.9520 - val_loss: 0.1154 - val_accuracy: 0.9551\n",
    "Epoch 93/100\n",
    "210/210 - 100s - loss: 0.1356 - accuracy: 0.9503 - val_loss: 0.1419 - val_accuracy: 0.9475\n",
    "Epoch 94/100\n",
    "210/210 - 100s - loss: 0.1183 - accuracy: 0.9544 - val_loss: 0.1217 - val_accuracy: 0.9551\n",
    "Epoch 95/100\n",
    "210/210 - 100s - loss: 0.1289 - accuracy: 0.9470 - val_loss: 0.1322 - val_accuracy: 0.9542\n",
    "Epoch 96/100\n",
    "210/210 - 101s - loss: 0.1211 - accuracy: 0.9546 - val_loss: 0.1266 - val_accuracy: 0.9494\n",
    "Epoch 97/100\n",
    "210/210 - 100s - loss: 0.1254 - accuracy: 0.9527 - val_loss: 0.1229 - val_accuracy: 0.9551\n",
    "Epoch 98/100\n",
    "210/210 - 100s - loss: 0.1166 - accuracy: 0.9553 - val_loss: 0.1201 - val_accuracy: 0.9475\n",
    "Epoch 99/100\n",
    "210/210 - 101s - loss: 0.1254 - accuracy: 0.9503 - val_loss: 0.1167 - val_accuracy: 0.9494\n",
    "Epoch 100/100\n",
    "210/210 - 100s - loss: 0.1119 - accuracy: 0.9584 - val_loss: 0.1157 - val_accuracy: 0.9570"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How did the training go?\n",
    "![](artifacts/charts/basic_cnn_model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3-learn-env]",
   "language": "python",
   "name": "conda-env-Anaconda3-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
